# pgAnalytics v3.3.0 - Detailed Implementation Plan

**Version**: 3.3.0 (Enterprise Foundations)
**Duration**: 4 weeks (January 2 - January 29, 2026)
**Team Size**: 2-3 developers
**Objective**: Add enterprise features required for large-scale production deployments

---

## Summary

v3.3.0 focuses on **6 critical enterprise features** that are partially missing from v3.2.0:

| Feature | Priority | Effort | Week |
|---------|----------|--------|------|
| Kubernetes Support | CRITICAL | 40 hours | 1-2 |
| High Availability | CRITICAL | 35 hours | 1-2 |
| Enterprise Auth | HIGH | 50 hours | 2-3 |
| Encryption at Rest | HIGH | 45 hours | 2-3 |
| Audit Logging | HIGH | 40 hours | 3-4 |
| Backup & DR | CRITICAL | 50 hours | 3-4 |

**Total Effort**: ~260 hours (13 weeks-days for 2.5 person team)

---

## Week 1: Kubernetes Support & HA Foundation

### Goal
Enable deployment on Kubernetes with Helm charts and document HA architecture.

### Task 1.1: Kubernetes Manifests (20 hours)

**Subtasks**:

1. **Create StatefulSet for Backend** (6 hours)
   - File: `kubernetes/backend-statefulset.yaml`
   - Requirements:
     - 3 replicas (configurable)
     - Resource limits (CPU 500m, Memory 512Mi)
     - Health checks (liveness, readiness, startup)
     - Init containers for migrations
     - Volume mounts for TLS
   - Implementation:
     ```yaml
     apiVersion: apps/v1
     kind: StatefulSet
     metadata:
       name: pganalytics-backend
     spec:
       serviceName: pganalytics-backend
       replicas: 3
       template:
         spec:
           initContainers:
             - name: migrate
               image: pganalytics-api:latest
               command: ["./pganalytics-api", "migrate", "up"]
           containers:
             - name: api
               livenessProbe:
                 httpGet:
                   path: /api/v1/health
                   port: 8080
               readinessProbe:
                 httpGet:
                   path: /api/v1/health
                   port: 8080
                 initialDelaySeconds: 10
     ```

2. **Create DaemonSet for Collectors** (6 hours)
   - File: `kubernetes/collector-daemonset.yaml`
   - One pod per node
   - Auto-registration with backend
   - Node affinity for database-adjacent nodes

3. **Create ConfigMaps & Secrets** (5 hours)
   - Files:
     - `kubernetes/configmap-backend.yaml`
     - `kubernetes/secret-tls.yaml`
     - `kubernetes/secret-credentials.yaml`
   - Content: Configuration from environment variables

4. **Create Services & Ingress** (3 hours)
   - Files:
     - `kubernetes/backend-service.yaml` (ClusterIP + NodePort)
     - `kubernetes/collector-service.yaml`
     - `kubernetes/ingress.yaml` (for external access)

**Deliverables**:
- 10 Kubernetes YAML files
- All with comments and placeholder values
- Test manifests for quick validation

---

### Task 1.2: Helm Chart Creation (20 hours)

**Subtasks**:

1. **Helm Chart Structure** (5 hours)
   - Directory: `helm/pganalytics/`
   - Files:
     ```
     helm/pganalytics/
     ├── Chart.yaml           # Chart metadata
     ├── values.yaml          # Default values (500+ lines)
     ├── charts/              # Dependency charts (if any)
     ├── templates/
     │   ├── NOTES.txt
     │   ├── backend-statefulset.yaml
     │   ├── collector-daemonset.yaml
     │   ├── backend-service.yaml
     │   ├── backend-hpa.yaml
     │   ├── configmap.yaml
     │   ├── secret.yaml
     │   ├── ingress.yaml
     │   ├── pvc.yaml
     │   └── rbac.yaml
     └── values-production.yaml # Production overrides
     ```

2. **Chart.yaml** (2 hours)
   - Name: pganalytics
   - Version: 3.3.0
   - AppVersion: 3.3.0
   - Keywords, description, icon
   - Maintainers
   - Dependencies (PostgreSQL, Redis charts optional)

3. **values.yaml** (8 hours)
   - All configurable parameters (500+ lines)
   - Backend config:
     ```yaml
     backend:
       replicaCount: 3
       image:
         repository: pganalytics/api
         tag: "3.3.0"
         pullPolicy: IfNotPresent

       resources:
         limits:
           cpu: 500m
           memory: 512Mi
         requests:
           cpu: 250m
           memory: 256Mi

       autoscaling:
         enabled: true
         minReplicas: 3
         maxReplicas: 10
         targetCPUUtilizationPercentage: 70
     ```

   - Collector config, database config, TLS config, etc.
   - Production-specific overrides

4. **Template Variables** (5 hours)
   - Ensure all templates use `{{ .Values.* }}`
   - Support multiple environments
   - Add conditional blocks for optional features

**Deliverables**:
- Complete Helm chart (production-ready)
- values-development.yaml
- values-production.yaml
- values-enterprise.yaml (with all options)
- `helm/pganalytics/README.md` with instructions

---

### Task 1.3: Documentation (15 hours)

**Files to Create**:

1. **KUBERNETES_DEPLOYMENT.md** (8 hours)
   - Prerequisites (kubectl, helm, cluster version)
   - Installation instructions:
     ```bash
     helm repo add pganalytics https://charts.pganalytics.io
     helm repo update
     helm install pganalytics pganalytics/pganalytics \
       --namespace pganalytics \
       --create-namespace \
       -f values-production.yaml
     ```
   - Verification steps
   - Troubleshooting guide
   - Common configurations (AWS EKS, GCP GKE, Azure AKS)

2. **HELM_VALUES_REFERENCE.md** (7 hours)
   - Reference for all 100+ values
   - Default values shown
   - Explanation of each setting
   - Examples for common scenarios

**Deliverables**:
- 2 comprehensive markdown files
- Installation steps verified on test cluster
- Common scenarios documented

---

### Task 1.4: Testing (10 hours)

**Test Plan**:

1. **Unit Tests** (5 hours)
   - Test YAML template rendering
   - `make test-helm` target
   - Files: `helm/pganalytics/tests/*.sh`

2. **Integration Tests** (5 hours)
   - Helm lint validation
   - Chart dependencies check
   - Deploy to test cluster
   - Run health checks on deployed pods
   - Verify all pods ready within 5 minutes
   - Test ingress connectivity
   - Verify collectors auto-register

**Deliverables**:
- Automated helm validation script
- Test cluster deployment verification
- CI/CD integration for helm testing

**Success Criteria for Week 1**:
- ✅ `helm install` succeeds on test cluster
- ✅ All pods reach Ready state within 5 minutes
- ✅ Health checks passing
- ✅ Collectors auto-register with backend
- ✅ Documentation complete and verified

---

## Week 2: High Availability Load Balancing

### Goal
Enable multi-backend deployments with automatic failover and load distribution.

### Task 2.1: Backend Stateless Refactoring (20 hours)

**Subtasks**:

1. **Identify Stateful Components** (5 hours)
   - Review `backend/internal/api/handlers.go`
   - Check for in-memory session storage
   - Identify any file-based state
   - List all state that needs to be moved

2. **Implement Distributed Caching** (10 hours)
   - Redis cache layer:
     ```go
     // File: backend/internal/cache/redis_cache.go
     type RedisCache struct {
         client *redis.Client
     }

     func (rc *RedisCache) Get(ctx context.Context, key string) (interface{}, error) {
         // Implementation
     }

     func (rc *RedisCache) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
         // Implementation
     }
     ```

   - Session storage in Redis (JWT tokens, user sessions)
   - Collector registration cache (distributed)

3. **Implement Idempotency** (5 hours)
   - Idempotency keys for API requests
   - Duplicate request detection
   - Exactly-once semantics for critical operations
   - Implementation:
     ```go
     // File: backend/internal/api/middleware.go
     func IdempotencyMiddleware(c *gin.Context) {
         idempotencyKey := c.GetHeader("Idempotency-Key")
         // Check cache for previous response
         // Return cached response if found
         // Otherwise process request
         c.Next()
         // Cache response with idempotency key
     }
     ```

**Deliverables**:
- Redis integration in backend
- Session storage using Redis
- Idempotency implementation for all state-changing endpoints
- Unit tests for distributed cache

---

### Task 2.2: Load Balancer Configuration (25 hours)

**Subtasks**:

1. **HAProxy Configuration** (8 hours)
   - File: `config/haproxy.cfg`
   - Configuration:
     ```haproxy
     global
         maxconn 4096
         log 127.0.0.1 local1 notice

     defaults
         log     global
         mode    http
         option  httplog
         option  dontlognull
         timeout connect 5000
         timeout client  50000
         timeout server  50000

     frontend frontend_http
         bind *:80
         redirect scheme https code 301 if !{ ssl_fc }

     frontend frontend_https
         bind *:443 ssl crt /etc/ssl/pganalytics/cert.pem
         default_backend backend_servers

     backend backend_servers
         balance roundrobin
         option httpchk GET /api/v1/health
         server backend1 backend1:8080 check inter 5000
         server backend2 backend2:8080 check inter 5000
         server backend3 backend3:8080 check inter 5000
     ```

2. **Nginx Configuration** (8 hours)
   - File: `config/nginx.conf`
   - Features:
     - Load balancing
     - SSL/TLS termination
     - Rate limiting
     - Request/response logging
     - Health checks

3. **Cloud LB Configurations** (5 hours)
   - AWS ALB (Application Load Balancer)
     - Target group configuration
     - Health check settings
     - Listener rules
   - Google Cloud Load Balancer
   - Azure Load Balancer

4. **Health Check Configuration** (4 hours)
   - Enhanced `/api/v1/health` endpoint
   - Return database connection status
   - Return cache connection status
   - Return collector count

**Deliverables**:
- HAProxy config (production-ready)
- Nginx config (production-ready)
- Cloud provider configs (AWS, GCP, Azure)
- Health check implementation
- Documentation for each setup

---

### Task 2.3: Failover & Session Management (20 hours)

**Subtasks**:

1. **Connection Draining** (5 hours)
   - Graceful shutdown procedure
   - Drain existing connections
   - Stop accepting new connections
   - File: `backend/internal/api/shutdown.go`
   - Implementation:
     ```go
     func (s *Server) Shutdown(ctx context.Context) error {
         // Stop accepting new connections
         // Wait for existing requests to complete
         // Maximum 30 second timeout
         return s.httpServer.Shutdown(ctx)
     }
     ```

2. **Distributed Session Tracking** (8 hours)
   - User sessions in Redis
   - Session timeout handling
   - Active session count tracking
   - Session invalidation on logout

3. **Health Check Enhancements** (4 hours)
   - Database connectivity check
   - Cache connectivity check
   - Metrics ingestion health
   - Collector communication health

4. **Failover Testing** (3 hours)
   - Automated failover test scripts
   - Simulated backend failure
   - Verify request routing to healthy backends
   - Verify no data loss on failover

**Deliverables**:
- Graceful shutdown implementation
- Enhanced health endpoint
- Session management in Redis
- Failover test scripts
- Documentation for failover procedures

---

### Task 2.4: Documentation & Testing (15 hours)

**Deliverables**:
- `docs/LOAD_BALANCING.md` (architecture guide)
- `docs/HA_DEPLOYMENT.md` (step-by-step setup)
- Load balancer configuration reference
- Failover testing procedures
- Disaster recovery runbook

**Success Criteria for Week 2**:
- ✅ Multiple backends can run simultaneously
- ✅ Requests balanced across backends
- ✅ One backend failure does not interrupt service
- ✅ Failover occurs <2 seconds
- ✅ No request loss on failover
- ✅ Documentation complete

---

## Week 3: Enterprise Authentication & Encryption

### Goal
Add LDAP, SAML, and encryption at rest support for enterprise deployments.

### Task 3.1: LDAP Integration (25 hours)

**Subtasks**:

1. **LDAP Client Implementation** (12 hours)
   - File: `backend/internal/auth/ldap.go`
   - Features:
     - Connect to LDAP server (with TLS)
     - User authentication (bind)
     - Group membership queries
     - User attribute extraction
     - Connection pooling
   - Code structure:
     ```go
     type LDAPClient struct {
         url      string
         bindDN   string
         bindPW   string
         baseDN   string
         conn     *ldap.Conn
     }

     func (lc *LDAPClient) AuthenticateUser(username, password string) (bool, error)
     func (lc *LDAPClient) GetUserAttributes(username string) (map[string]string, error)
     func (lc *LDAPClient) GetGroupMembership(username string) ([]string, error)
     ```

2. **Group-Based RBAC** (8 hours)
   - Map LDAP groups to application roles
   - Configuration:
     ```yaml
     ldap:
       groups:
         admin_ldap_group: "CN=pganalytics-admins,OU=Groups"
         user_ldap_group: "CN=pganalytics-users,OU=Groups"
         viewer_ldap_group: "CN=pganalytics-viewers,OU=Groups"
     ```

3. **User Sync** (5 hours)
   - Periodic user sync from LDAP
   - Update roles from group membership
   - Remove access for deactivated users
   - Cron job or background task

**Deliverables**:
- LDAP integration in auth package
- LDAP configuration management
- Group-to-role mapping
- User sync background job
- Unit tests for LDAP operations

---

### Task 3.2: SAML 2.0 Support (25 hours)

**Subtasks**:

1. **SAML Service Provider** (15 hours)
   - File: `backend/internal/auth/saml.go`
   - Features:
     - Metadata endpoint (`/api/v1/saml/metadata`)
     - Assertion Consumer Service endpoint (`/api/v1/saml/acs`)
     - Login redirect
     - Assertion validation
   - Dependencies: `github.com/crewjam/saml`

2. **SAML Configuration** (5 hours)
   - Idp metadata URL configuration
   - Certificate configuration
   - Attribute mappings (username, email, groups)

3. **Session Management** (5 hours)
   - Create JWT from SAML assertion
   - Session tracking
   - Logout handling

**Deliverables**:
- SAML service provider implementation
- SAML configuration guide
- Metadata endpoint
- Unit tests

---

### Task 3.3: Encryption at Rest (30 hours)

**Subtasks**:

1. **Database Column Encryption** (15 hours)
   - PostgreSQL pgcrypto extension
   - File: `backend/internal/crypto/crypto.go`
   - Encrypt sensitive columns:
     - users.password_hash
     - api_tokens.token
     - collector_config.values (configuration)
     - alerts.webhook_url (contains credentials)
   - Implementation:
     ```go
     func EncryptValue(plaintext string, key []byte) (string, error)
     func DecryptValue(ciphertext string, key []byte) (string, error)
     ```

2. **Key Management** (10 hours)
   - Environment variable for encryption key
   - Key rotation procedures
   - Hashicorp Vault integration (optional)
   - Key versioning

3. **Database Migration** (5 hours)
   - Migration script: `backend/migrations/006_encryption.sql`
   - Encrypt existing data
   - Rollback procedures

**Deliverables**:
- Encryption/decryption functions
- Database encryption setup
- Key management guide
- Migration scripts
- Unit tests

---

### Task 3.4: Documentation (10 hours)

**Deliverables**:
- `docs/ENTERPRISE_AUTH.md` (LDAP/SAML setup)
- `docs/LDAP_CONFIGURATION.md` (LDAP-specific)
- `docs/SAML_CONFIGURATION.md` (SAML-specific)
- `docs/ENCRYPTION_AT_REST.md` (encryption guide)
- Configuration examples for popular LDAP/SAML providers

**Success Criteria for Week 3**:
- ✅ LDAP authentication working
- ✅ SAML authentication working
- ✅ User groups mapped to roles
- ✅ Sensitive data encrypted in database
- ✅ Key rotation tested

---

## Week 4: Audit Logging & Backup/DR

### Goal
Implement comprehensive audit logging and automated backup/disaster recovery.

### Task 4.1: Audit Logging (25 hours)

**Subtasks**:

1. **Audit Log Table** (5 hours)
   - Migration: `backend/migrations/007_audit_logging.sql`
   - Schema:
     ```sql
     CREATE TABLE audit_logs (
         id BIGSERIAL PRIMARY KEY,
         timestamp TIMESTAMPTZ DEFAULT now(),
         user_id UUID REFERENCES users(id),
         action VARCHAR(100),
         resource_type VARCHAR(100),
         resource_id VARCHAR(255),
         changes JSONB,
         ip_address INET,
         user_agent TEXT
     );
     CREATE INDEX idx_audit_logs_timestamp ON audit_logs(timestamp DESC);
     CREATE INDEX idx_audit_logs_user_id ON audit_logs(user_id);
     ```

2. **Audit Middleware** (10 hours)
   - File: `backend/internal/api/middleware.go`
   - Log all API requests
   - Track data changes (before/after)
   - Immutable audit trail
   - Performance-optimized (async writes)
   - Example:
     ```go
     func AuditLoggingMiddleware(c *gin.Context) {
         // Capture request details
         // Process request
         c.Next()
         // Log to audit_logs table asynchronously
     }
     ```

3. **Audit Log Visualization** (5 hours)
   - Grafana dashboard for audit logs
   - Search and filter capabilities
   - User activity tracking
   - Change history

4. **Compliance Features** (5 hours)
   - GDPR data access request support
   - SOX compliance logging
   - HIPAA audit trail requirements
   - Log retention policies

**Deliverables**:
- Audit logging implementation
- Audit middleware
- Grafana dashboard
- Compliance documentation
- Unit tests

---

### Task 4.2: Backup & Disaster Recovery (30 hours)

**Subtasks**:

1. **Automated Backup System** (15 hours)
   - File: `scripts/backup.sh` (400+ lines)
   - Features:
     - PostgreSQL streaming backups
     - TimescaleDB incremental backups
     - Backup scheduling (daily, 2:00 AM)
     - Retention policy (30 days)
     - Encryption (GPG)
     - Compression (gzip)
   - Example script structure:
     ```bash
     #!/bin/bash

     # PostgreSQL backup
     pg_basebackup -h $DB_HOST -U postgres \
       -D /backups/pg-$(date +%Y%m%d) -Ft -z -P

     # TimescaleDB backup
     pg_dump -h $TS_HOST -U postgres metrics | gzip > \
       /backups/ts-$(date +%Y%m%d).sql.gz

     # Encrypt
     gpg --encrypt --recipient $GPG_KEY /backups/*

     # Upload to S3
     aws s3 cp /backups/ s3://pganalytics-backups/$(date +%Y%m%d)/ \
       --recursive --sse=AES256
     ```

2. **Restore Automation** (10 hours)
   - File: `scripts/restore.sh` (300+ lines)
   - Support:
     - Point-in-time recovery (PITR)
     - Verification of restore
     - Parallel restore for speed
   - Usage:
     ```bash
     ./restore.sh --date 2026-02-25 --type pitr --target-time "14:30:00"
     ```

3. **Backup Verification** (5 hours)
   - File: `scripts/backup-verify.sh` (200+ lines)
   - Daily verification:
     - Backup file integrity
     - Restore test on standby
     - Notification on failure

**Deliverables**:
- Automated backup scripts
- Restore scripts with PITR
- Backup verification
- CI/CD integration
- Disaster recovery runbook
- RTO/RPO testing results

---

### Task 4.3: Testing & Documentation (20 hours)

**Deliverables**:
- `docs/BACKUP_AND_RECOVERY.md` (comprehensive guide)
- `docs/DISASTER_RECOVERY_PLAN.md` (procedures)
- Monthly DR drill results
- RTO testing (target <1 hour)
- RPO testing (target <5 minutes)
- Backup verification dashboard

**Success Criteria for Week 4**:
- ✅ Daily backups run automatically
- ✅ Backup verification passes
- ✅ Restore tested monthly
- ✅ RTO <1 hour demonstrated
- ✅ RPO <5 minutes achieved
- ✅ Audit logs recorded for all changes
- ✅ Compliance requirements met

---

## Overall Project Metrics

### Development Effort
- **Total Hours**: ~260 hours
- **Team Size**: 2-3 developers
- **Duration**: 4 weeks
- **Average per week**: 65 hours

### Code Changes
- **New Go Code**: ~2,500 lines
- **New SQL**: ~500 lines
- **New YAML/Config**: ~1,500 lines
- **New Documentation**: ~3,000 lines
- **New Tests**: ~1,000 lines

### Testing Coverage
- **Unit Tests**: +50 tests
- **Integration Tests**: +20 tests
- **E2E Tests**: +10 tests
- **Load Tests**: TBD by v3.4.0

---

## Risk Management

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|-----------|
| Kubernetes YAML errors | Medium | Medium | Helm lint + test cluster |
| Redis session loss | Low | High | Configure persistence |
| LDAP connectivity | Low | Medium | Fallback to local auth |
| Encryption key loss | Very Low | Critical | Vault + backup keys |
| Audit log performance | Medium | Low | Async writes + partitioning |

---

## Approval & Sign-Off

**Awaiting Approval From**: Glauco Torres (Project Owner)

**Implementation Lead**: TBD
**Timeline**: January 2-29, 2026
**Target Release**: v3.3.0 GA (February 15, 2026)

---

*This plan is detailed and ready for implementation. All deliverables are defined with success criteria.*
